{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.keras import layers, models\n",
    "from utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data to [train, validation] from (x_train), test set (x_test)\n",
    "# get train set and test set from tf.keras\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "(x_validation, y_validation) = (x_train[50000:-1], y_train[50000:-1])\n",
    "(x_train, y_train) = (x_train[0:50000], y_train[0:50000])\n",
    "\n",
    "# # summaries data \n",
    "# print(\"trainset: \\n\")\n",
    "# summary_data(x_train, y_train)\n",
    "# print(\"validation: \\n\")\n",
    "# summary_data(x_validate, y_validate)\n",
    "# print(\"testset: \\n\")\n",
    "# summary_data(x_test, y_test)\n",
    "\n",
    "# processed_x_train = preprocessing(x_train)\n",
    "# processed_x_validate = preprocessing(x_validate)\n",
    "# processed_x_test = preprocessing(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show sample images \n",
    "get_sample_data(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # full data \n",
    "# # # training and validation_data \n",
    "# # # config: optimizer = \"adam\"\n",
    "# # # loss_function = sparse_categorical_crossentropy\n",
    "# # # metrics = accuracy\n",
    "# # #train with \n",
    "# model_training_v0 = get_light_model(image_size = (28,28,1))\n",
    "# model_v0, history_v0 = train(model_training_v0, processed_x_train,y_train, processed_x_validate,y_validate, batch_size=1024, epochs=10)\n",
    "# show_history(history_v0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get 1% subsampling train data\n",
    "numb_images = x_train.shape[0]\n",
    "numb_samples = int(numb_images * 0.01)\n",
    "x_train_subsamples = preprocessing_gan(x_train[0:numb_samples])\n",
    "y_train_subsamples = y_train[0:numb_samples]\n",
    "\n",
    "\n",
    "numb_samples = int(numb_images * 0.01)\n",
    "x_validation_subsamples = preprocessing_gan(x_validation[0:numb_samples])\n",
    "y_validation_subsamples = y_validation[0:numb_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"subsampling: \\n\")\n",
    "# summary_data(x_train_subsamples, y_train_subsamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full data \n",
    "# training and validation_data \n",
    "# config: optimizer = \"adam\"\n",
    "# loss_function = sparse_categorical_crossentropy\n",
    "# metrics = accuracy\n",
    "#train with \n",
    "\n",
    "model_training_v1 = get_light_model(image_size = (28,28,1))\n",
    "model_v1, history_v1 = train(model_training_v1, x_train_subsamples, y_train_subsamples, x_validate,y_validate, batch_size=128)\n",
    "show_history(history_v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate data by GAN model \n",
    "from gan_generator import *\n",
    "d_model = define_discriminator_model()\n",
    "\n",
    "g_model = define_generator_model(100)\n",
    "\n",
    "gan_model = define_gan(g_model,d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-1e9c8411e1ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m           \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train_subsamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train_subsamples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m           \u001b[0mvalidate_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_validation_subsamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_validation_subsamples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m           latent_dim=100)\n\u001b[0m",
      "\u001b[0;32m~/vinid/gan_generator.py\u001b[0m in \u001b[0;36mtrain_gan\u001b[0;34m(g_model, d_model, gan_model, data, label, validate_data, validate_label, latent_dim, epochs, numb_batch)\u001b[0m\n\u001b[1;32m    100\u001b[0m       x_fake, y_fake = generate_fake_samples(g_model, latent_dim,\n\u001b[1;32m    101\u001b[0m                                              \u001b[0;31m#devide 10 to balance data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m                                              haft_data_point_batch / 10)\n\u001b[0m\u001b[1;32m    103\u001b[0m       \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_fake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_real\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_fake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_real\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/vinid/gan_generator.py\u001b[0m in \u001b[0;36mgenerate_fake_samples\u001b[0;34m(g_model, latent_dim, numb_samples)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;31m# using generator to generate n fake samples, with class labels:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgenerate_fake_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumb_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m   \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_latent_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumb_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m   \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m   \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumb_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/vinid/gan_generator.py\u001b[0m in \u001b[0;36mgenerate_latent_points\u001b[0;34m(latent_dim, numb_samples)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgenerate_latent_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumb_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_dim\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnumb_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumb_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.randn\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.standard_normal\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.cont0_array\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "# numb_samples = int(numb_images * 0.01)\n",
    "# x_train_subsamples = x_train[0:numb_samples]\n",
    "# y_train_subsamples = y_train[0:numb_samples]\n",
    "\n",
    "\n",
    "# numb_samples = int(numb_images * 0.01)\n",
    "# x_validation_subsamples = x_validation[0:numb_samples]\n",
    "# y_validation_subsamples = y_validation[0:numb_samples]\n",
    "\n",
    "\n",
    "train_gan(g_model=g_model, d_model=d_model, gan_model=gan_model, \n",
    "          data = x_train_subsamples, label = y_train_subsamples,\n",
    "          validate_data=x_validation_subsamples, validate_label=y_validation_subsamples, \n",
    "          latent_dim=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
